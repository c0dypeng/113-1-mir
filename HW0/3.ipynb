{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e51f0e",
   "metadata": {},
   "source": [
    "### Task3: Deep Learning Model\n",
    "\n",
    "- Train a deep learning model (e.g. CNN or attention based model) with Mel-spectrograms extracted from the audio as input\n",
    "\n",
    "- Need to compare 2 different kinds of inputs: Mel-spectrograms with or without taking the log\n",
    "\n",
    "- You can choose whatever FFT window size and hop length you like\n",
    "\n",
    "- You can choose whatever deep learning model you like\n",
    "\n",
    "- Need to report how to implement the model clearly\n",
    "\n",
    "- Need to report the testing result (not validation result) with confusion matrix, top1 accuracy, and top3 accuracy\n",
    "\n",
    "- You can use any music tagging model. For a novice, the short chunk CNN in this repo is recommended. (Need to replace the BCE loss to Cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536f6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset file path:\n",
    "# traning_data_path = '<PUT THE PATH TO THE TRAINING DATA HERE>'\n",
    "\n",
    "traning_data_path = 'nsynth-subtrain'\n",
    "\n",
    "# test_data_path = '<PUT THE PATH TO THE TEST DATA HERE>'\n",
    "test_data_path = 'nsynth-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596aba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "import librosa\n",
    "import torchaudio\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "import joblib\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db58b348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flute', 'keyboard', 'organ', 'brass', 'vocal', 'reed', 'mallet', 'string', 'guitar', 'bass', 'synth_lead'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['instrument_family_str.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the json file\n",
    "def load_json(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# let the json path be /examples.json under the \"traning_data_path\"\n",
    "json_path = os.path.join(traning_data_path, 'examples.json')\n",
    "\n",
    "data = load_json(json_path)\n",
    "\n",
    "# get all \"instrument_family_str\"\n",
    "instrument_family_str = set()\n",
    "for key in data:\n",
    "    instrument_family_str.add(data[key][\"instrument_family_str\"])\n",
    "\n",
    "print(instrument_family_str)\n",
    "\n",
    "# dump the instrument_family_str into a pickle file\n",
    "joblib.dump(instrument_family_str, \"instrument_family_str.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44de218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all keys in data\n",
    "keys = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe41d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(key, file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "\n",
    "    # FFT window size=2048, and the hop length=512\n",
    "    # extract the mel spectrogram feature\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=512, hop_length=512)\n",
    "\n",
    "    # extract the mel spectrogram feature with log scaling\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "\n",
    "    # put all features into a list\n",
    "    features = [mel_spectrogram, log_mel_spectrogram]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97f0ef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48037/48037 [03:01<00:00, 264.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# extract the features from each audio file\n",
    "\n",
    "features = []\n",
    "\n",
    "# for file in keys:\n",
    "for key in tqdm.tqdm(keys):\n",
    "    file = os.path.join(traning_data_path, 'audio', key + '.wav')\n",
    "    # extract the features\n",
    "    feature = feature_extraction(key, file)\n",
    "    features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c3ede72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = [f[0] for f in features]\n",
    "log_mel_spectrogram = [f[1] for f in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a84b9e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 173)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the features\n",
    "print(mel_spectrogram[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b205b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one hot encoding of the labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Extract labels from the data\n",
    "labels = [data[key][\"instrument_family_str\"] for key in keys]\n",
    "\n",
    "# Initialize the LabelEncoder and OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert string labels to integer labels\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Reshape integer_encoded to 2D array (necessary for OneHotEncoder)\n",
    "integer_encoded = integer_encoded.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92bd4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(mel_spectrogram)\n",
    "y = integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d7d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea81a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_2d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size=3, stride=1, pooling=2):\n",
    "        super(Conv_2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, kernel_size, stride=stride, padding=kernel_size//2)\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mp = nn.MaxPool2d(pooling)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.mp(self.relu(self.bn(self.conv(x))))\n",
    "        return out\n",
    "\n",
    "class ShortChunkCNN(nn.Module):\n",
    "    '''\n",
    "    Short-chunk CNN architecture.\n",
    "    So-called VGG-like model with a small receptive field.\n",
    "    Deeper layers, smaller pooling (2x2).\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 n_channels=128,\n",
    "                 n_class=11):\n",
    "        super(ShortChunkCNN, self).__init__()\n",
    "\n",
    "        # CNN Layers\n",
    "        self.layer1 = Conv_2d(1, n_channels, pooling=2)\n",
    "        self.layer2 = Conv_2d(n_channels, n_channels, pooling=2)\n",
    "        self.layer3 = Conv_2d(n_channels, n_channels*2, pooling=2)\n",
    "        self.layer4 = Conv_2d(n_channels*2, n_channels*2, pooling=2)\n",
    "        self.layer5 = Conv_2d(n_channels*2, n_channels*2, pooling=2)\n",
    "        self.layer6 = Conv_2d(n_channels*2, n_channels*2, pooling=2)\n",
    "        self.layer7 = Conv_2d(n_channels*2, n_channels*4, pooling=2)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.dense1 = nn.Linear(n_channels*4, n_channels*4)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channels*4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(n_channels*4, n_class)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 1, 128, 137)\n",
    "\n",
    "        # CNN Forward Pass\n",
    "        x = self.layer1(x)  # -> (batch_size, n_channels, H/2, W/2)\n",
    "        x = self.layer2(x)  # -> (batch_size, n_channels, H/4, W/4)\n",
    "        x = self.layer3(x)  # -> (batch_size, n_channels*2, H/8, W/8)\n",
    "        x = self.layer4(x)  # -> (batch_size, n_channels*2, H/16, W/16)\n",
    "        x = self.layer5(x)  # -> (batch_size, n_channels*2, H/32, W/32)\n",
    "        x = self.layer6(x)  # -> (batch_size, n_channels*2, H/64, W/64)\n",
    "        x = self.layer7(x)  # -> (batch_size, n_channels*4, H/128, W/128)\n",
    "\n",
    "        # 確保特徵圖的寬度為1，進行全局池化\n",
    "        if x.size(3) != 1:\n",
    "            x = nn.MaxPool2d(kernel_size=(1, x.size(3)))(x)\n",
    "        x = x.squeeze(3)  # -> (batch_size, n_channels*4, H/128)\n",
    "\n",
    "        # 全局池化後，如果高度仍大於1，進行一次全局池化\n",
    "        if x.size(2) != 1:\n",
    "            x = nn.MaxPool1d(x.size(2))(x)\n",
    "        x = x.squeeze(2)  # -> (batch_size, n_channels*4)\n",
    "\n",
    "        # 全連接層\n",
    "        x = self.dense1(x)          # -> (batch_size, n_channels*4)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)          # -> (batch_size, n_class)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a981dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 1/3003, Loss: 2.3802\n",
      "batch number: 2/3003, Loss: 2.3107\n",
      "batch number: 3/3003, Loss: 2.1719\n",
      "batch number: 4/3003, Loss: 2.0860\n",
      "batch number: 5/3003, Loss: 2.0586\n",
      "batch number: 6/3003, Loss: 2.0095\n",
      "batch number: 7/3003, Loss: 1.9971\n",
      "batch number: 8/3003, Loss: 1.9764\n",
      "batch number: 9/3003, Loss: 1.8757\n",
      "batch number: 10/3003, Loss: 1.9195\n",
      "batch number: 11/3003, Loss: 1.8452\n",
      "batch number: 12/3003, Loss: 1.7953\n",
      "batch number: 13/3003, Loss: 1.8448\n",
      "batch number: 14/3003, Loss: 1.7938\n",
      "batch number: 15/3003, Loss: 1.7205\n",
      "batch number: 16/3003, Loss: 1.7016\n",
      "batch number: 17/3003, Loss: 1.7317\n",
      "batch number: 18/3003, Loss: 1.7250\n"
     ]
    }
   ],
   "source": [
    "# with GPU\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the x and y into the data loader\n",
    "train_loader = DataLoader(dataset=list(zip(x, y)), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = ShortChunkCNN(n_channels=128, n_class=11)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 訓練迴圈\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    for inputs, integer_labels in train_loader:\n",
    "        # 假設 inputs 的形狀為 (batch_size, 128, 137)\n",
    "        inputs = inputs.unsqueeze(1)  # -> (batch_size, 1, 128, 137)\n",
    "        # labels: from 0 to 10\n",
    "        labels = integer_labels.squeeze() # -> (batch_size)\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # -> (batch_size, n_class)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print batch number \n",
    "        print(f'batch number: {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "        batch_idx += 1\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'mel_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc51d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model\n",
    "model = ShortChunkCNN(n_channels=128, n_class=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b170b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# load the test data\n",
    "test_data = load_json(os.path.join(test_data_path, 'examples.json'))\n",
    "test_keys = list(test_data.keys())\n",
    "test_features = []\n",
    "for key in test_keys:\n",
    "    file = os.path.join(test_data_path, 'audio', key + '.wav')\n",
    "    feature = feature_extraction(key, file)\n",
    "    test_features.append(feature)\n",
    "\n",
    "test_mel_spectrogram = [f[0] for f in test_features]\n",
    "\n",
    "test_labels = [test_data[key][\"instrument_family_str\"] for key in test_keys]\n",
    "test_integer_encoded = label_encoder.fit_transform(test_labels)\n",
    "test_integer_encoded = test_integer_encoded.reshape(-1, 1)\n",
    "\n",
    "# Reshape integer_encoded to 2D array (necessary for OneHotEncoder)\n",
    "integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "\n",
    "test_x = np.array(test_mel_spectrogram)\n",
    "# test_x = np.expand_dims(test_x, axis=1)\n",
    "test_y = test_integer_encoded\n",
    "\n",
    "# load the test data into the data loader\n",
    "test_loader = DataLoader(dataset=list(zip(test_x, test_y)), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e118463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 173)\n"
     ]
    }
   ],
   "source": [
    "print(test_mel_spectrogram[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "234eeec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 128, 173)\n",
      "(4096, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a7806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/rxqxvrmd0z1bnnny3trbtfz80000gn/T/ipykernel_15977/561182298.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('mel_model.pth', ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 100.00%\n",
      "Top-3 Accuracy: 100.00%\n",
      "Confusion Matrix:\n",
      "[[4096]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    top1_correct = 0\n",
    "    top3_correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for batch_x, batch_y in test_loader:\n",
    "\n",
    "            batch_x = batch_x.unsqueeze(1)  # -> (batch_size, 1, 128, 137)\n",
    "            batch_y = batch_y.squeeze() # -> (batch_size)\n",
    "\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_x)\n",
    "            \n",
    "            # Get Top-1 predictions\n",
    "            _, top1_pred = torch.max(outputs, dim=1)\n",
    "            \n",
    "            # Get Top-3 predictions\n",
    "            _, top3_pred = torch.topk(outputs, k=3, dim=1)\n",
    "            \n",
    "            # Compute Top-1 accuracy\n",
    "            top1_correct += (top1_pred == batch_y.squeeze()).sum().item()\n",
    "            \n",
    "            # Compute Top-3 accuracy\n",
    "            top3_correct += (batch_y.squeeze().unsqueeze(1) == top3_pred).sum().item()\n",
    "\n",
    "            # Collect predictions and true labels for confusion matrix\n",
    "            all_preds.extend(top1_pred.cpu().numpy())\n",
    "            all_labels.extend(batch_y.squeeze().cpu().numpy())\n",
    "            \n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    # Calculate accuracies\n",
    "    top1_accuracy = top1_correct / total\n",
    "    top3_accuracy = top3_correct / total\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return top1_accuracy, top3_accuracy, conf_matrix\n",
    "\n",
    "\n",
    "# Example usage of the evaluate function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model (assuming model has already been defined and trained)\n",
    "model = ShortChunkCNN(n_channels=128, n_class=11)  # Adjust based on your model\n",
    "model.load_state_dict(torch.load('mel_model.pth', ))\n",
    "model.to(device)\n",
    "\n",
    "# Load the test data into the data loader\n",
    "test_loader = DataLoader(dataset=list(zip(test_x, test_y)), batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluate the model\n",
    "top1_acc, top3_acc, conf_matrix = evaluate(model, test_loader, device)\n",
    "\n",
    "# Print results\n",
    "print(f\"Top-1 Accuracy: {top1_acc * 100:.2f}%\")\n",
    "print(f\"Top-3 Accuracy: {top3_acc * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc253fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
